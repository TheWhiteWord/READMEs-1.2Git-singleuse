{
  "metadata": {
    "readmes_programming_system_": {
      "type": "section",
      "line": "# READMEs Programming System\r"
    },
    "readmes_programming_system_.system_configuration_": {
      "type": "section",
      "line": "## System Configuration\r"
    },
    "readmes_programming_system_.system_configuration_.llm_optimization_features_": {
      "type": "section",
      "line": "## LLM Optimization Features\r"
    },
    "readmes_programming_system_.system_configuration_.llm_optimization_features_.function_examples_": {
      "type": "section",
      "line": "## Function Examples\r"
    },
    "readmes_programming_system_.system_configuration_.llm_optimization_features_.function_examples_.function:_process_intent_": {
      "type": "section",
      "line": "# Function: process_intent\r"
    },
    "readmes_programming_system_.system_configuration_.llm_optimization_features_.function_examples_.function:_process_intent_.template:_llm_processor_": {
      "type": "section",
      "line": "# Template: llm_processor\r"
    },
    "readmes_programming_system_.system_configuration_.llm_optimization_features_.function_examples_.function:_process_intent_.template:_llm_processor_.warmhole:_intent_processor_": {
      "type": "section",
      "line": "# Warmhole: intent_processor\r"
    },
    "readmes_programming_system_.system_configuration_.llm_optimization_features_.function_examples_.function:_process_intent_.template:_llm_processor_.warmhole:_intent_processor_.quick_start_": {
      "type": "section",
      "line": "## Quick Start\r"
    }
  },
  "variables": {
    "readme_content": "# READMEs Programming System\r\n\r\nA self-contained programming system using README.md as executable documentation, powered by LLM-driven navigation and execution.\r\n\r\n## System Configuration\r\n```yaml\r\nversion: 1.2\r\nmetadata:\r\n  standalone: true\r\n  web_compatible: true\r\n  llm_driven: true\r\n  \r\ncontext:\r\n  enabled: true\r\n  warmhole_links: true\r\n  state_tracking: true\r\n  llm_control: true\r\n  \r\nvariables:\r\n  readme_content: \"\"\r\n  previous_output: \"\"\r\n  system_state: \"\"\r\n  llm_context: {}\r\n  warmhole_history: []\r\n```\r\n\r\n## LLM Optimization Features\r\n\r\n### Context Management\r\nThe LLM maintains and updates system context including:\r\n- Current warmhole state\r\n- Execution history\r\n- System goals and constraints\r\n- Previous outputs and results\r\n\r\n### Smart Navigation\r\nThe LLM automatically:\r\n- Decides which warmholes to navigate\r\n- Determines optimal execution paths\r\n- Creates or modifies warmholes as needed\r\n- Manages state transfers between warmholes\r\n\r\n### Autonomous Execution\r\nThe LLM:\r\n- Interprets user intent\r\n- Selects appropriate functions to execute\r\n- Provides input parameters\r\n- Validates outputs and handles errors\r\n- Documents changes and decisions\r\n\r\n## Function Examples\r\n\r\n### Natural Language Processing\r\n```markdown\r\n# Function: process_intent\r\n- description: \"Process user intent and determine execution path\"\r\n- input: message: string\r\n- output: plan: object\r\n- template: llm_processor\r\n- llm_context: true\r\n```\r\n\r\n### LLM Processor Template\r\n```markdown\r\n# Template: llm_processor\r\n- input_placeholder: \"{{message}}\"\r\n- transform: |\r\n    return llm.processUserIntent(context.message);\r\n- output_format: object\r\n- requires_llm: true\r\n```\r\n\r\n### Smart Navigation Example\r\n```markdown\r\n# Warmhole: intent_processor\r\n- description: \"Entry point for processing user requests\"\r\n- state_transfer: [\"user_intent\", \"system_context\"]\r\n- condition: \"llm.shouldActivate(context)\"\r\n- llm_context: {\r\n    purpose: \"Process and understand user intent\",\r\n    capabilities: [\"intent analysis\", \"path planning\", \"context management\"]\r\n  }\r\n```\r\n\r\n## Quick Start\r\n\r\n1. Send a request to the system:\r\n```javascript\r\nconst result = await system.process(\"Process this dataset and generate a report\");\r\n```\r\n\r\nThe LLM will:\r\n1. Analyze your intent\r\n2. Plan the execution path\r\n3. Navigate through appropriate warmholes\r\n4. Execute required functions\r\n5. Return results and documentation\r\n\r\n---\r\nüìù LLM-Driven README Programming System\r\nü§ñ Autonomous Navigation & Execution"
  },
  "currentContext": {
    "warmhole": "intent_processor",
    "readme_content": "# READMEs Programming System\r\n\r\nA self-contained programming system using README.md as executable documentation, powered by LLM-driven navigation and execution.\r\n\r\n## System Configuration\r\n```yaml\r\nversion: 1.2\r\nmetadata:\r\n  standalone: true\r\n  web_compatible: true\r\n  llm_driven: true\r\n  \r\ncontext:\r\n  enabled: true\r\n  warmhole_links: true\r\n  state_tracking: true\r\n  llm_control: true\r\n  \r\nvariables:\r\n  readme_content: \"\"\r\n  previous_output: \"\"\r\n  system_state: \"\"\r\n  llm_context: {}\r\n  warmhole_history: []\r\n```\r\n\r\n## LLM Optimization Features\r\n\r\n### Context Management\r\nThe LLM maintains and updates system context including:\r\n- Current warmhole state\r\n- Execution history\r\n- System goals and constraints\r\n- Previous outputs and results\r\n\r\n### Smart Navigation\r\nThe LLM automatically:\r\n- Decides which warmholes to navigate\r\n- Determines optimal execution paths\r\n- Creates or modifies warmholes as needed\r\n- Manages state transfers between warmholes\r\n\r\n### Autonomous Execution\r\nThe LLM:\r\n- Interprets user intent\r\n- Selects appropriate functions to execute\r\n- Provides input parameters\r\n- Validates outputs and handles errors\r\n- Documents changes and decisions\r\n\r\n## Function Examples\r\n\r\n### Natural Language Processing\r\n```markdown\r\n# Function: process_intent\r\n- description: \"Process user intent and determine execution path\"\r\n- input: message: string\r\n- output: plan: object\r\n- template: llm_processor\r\n- llm_context: true\r\n```\r\n\r\n### LLM Processor Template\r\n```markdown\r\n# Template: llm_processor\r\n- input_placeholder: \"{{message}}\"\r\n- transform: |\r\n    return llm.processUserIntent(context.message);\r\n- output_format: object\r\n- requires_llm: true\r\n```\r\n\r\n### Smart Navigation Example\r\n```markdown\r\n# Warmhole: intent_processor\r\n- description: \"Entry point for processing user requests\"\r\n- state_transfer: [\"user_intent\", \"system_context\"]\r\n- condition: \"llm.shouldActivate(context)\"\r\n- llm_context: {\r\n    purpose: \"Process and understand user intent\",\r\n    capabilities: [\"intent analysis\", \"path planning\", \"context management\"]\r\n  }\r\n```\r\n\r\n## Quick Start\r\n\r\n1. Send a request to the system:\r\n```javascript\r\nconst result = await system.process(\"Process this dataset and generate a report\");\r\n```\r\n\r\nThe LLM will:\r\n1. Analyze your intent\r\n2. Plan the execution path\r\n3. Navigate through appropriate warmholes\r\n4. Execute required functions\r\n5. Return results and documentation\r\n\r\n---\r\nüìù LLM-Driven README Programming System\r\nü§ñ Autonomous Navigation & Execution"
  },
  "warmholes": {
    "intent_processor": {
      "name": "intent_processor",
      "description": "Entry point for processing user requests",
      "state_transfer": [
        "\"user_intent\"",
        "\"system_context\""
      ],
      "condition": "llm.shouldActivate(context)"
    },
    "data_analyzer": {
      "name": "data_analyzer",
      "description": "Analyze the processed data",
      "state_transfer": [
        "\"analyzed_data\"",
        "\"analysis_report\""
      ],
      "condition": "llm.shouldAnalyze(context)"
    },
    "report_generator": {
      "name": "report_generator",
      "description": "Generate a report from the analyzed data",
      "state_transfer": [
        "\"final_report\""
      ],
      "condition": "llm.shouldGenerateReport(context)"
    },
    "completion": {
      "name": "completion",
      "description": "Complete the process",
      "state_transfer": [],
      "condition": "llm.shouldComplete(context)"
    }
  },
  "functions": {
    "process_intent": {
      "name": "process_intent",
      "description": "Process user intent and determine execution path",
      "input": {
        "name": "message",
        "type": "string"
      },
      "output": {
        "name": "plan",
        "type": "object"
      },
      "template": "llm_processor"
    }
  },
  "templates": {
    "llm_processor": {
      "name": "llm_processor",
      "placeholder": "{{message}}",
      "transform": "return llm.processUserIntent(context.message);",
      "outputFormat": "object"
    }
  },
  "cache": {},
  "llmContext": {
    "history": [],
    "goals": [],
    "decisions": [],
    "optimizations": []
  }
}